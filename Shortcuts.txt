#Colletions os tips and tricks froms several resources for my ML studies.

#Best IDE - Anaconda
# http://anaconda.org

#python spyder
#R studio

#Troubleshooting

#Rccp is getting error on instalation on R studio, just go to https://cran.r-project.org/web/packages/Rcpp/index.html
#download the Rcpp, unzip and past on R lib directory.  You can check out the path using the command .Library on Rstudio console


#Python

#Importing libraries and creating shortcuts for Data Preprocessing

import numpy as np
#library Plot charts
import matplotlib.pyplot as plt 
#Pandas library to import and manager dataset
import pandas as pd

#importing dataset, in this case it is Data.csv

dataset = pd.read_csv('Data.csv')


# : means all the column less the last one
X = dataset.iloc[:, :-1].values
Y = dataset.iloc[:, 3].values

#replacing missing data, for example when the value is null or there isn't
from sklearn.preprocessing import Imputer
imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)
imputer = imputer.fit(X[:, 1:3])
X[:, 1:3] = imputer.transform(X[:, 1:3])


#Enconding categorical data. This is important because in ML we can not work with strings in the dataset, so
#we pass all data to numbers

from sklearn.preprocessing import  LabelEncoder, OneHotEncoder
labelEncoder_X = LabelEncoder()
X[:, 0] = labelEncoder_X.fit_transform(X[:, 0])

onehotencoder = OneHotEncoder(categorical_features = [0])
X = onehotencoder.fit_transform(X).toarray()

labelEncoder_Y = LabelEncoder()
Y = labelEncoder_Y.fit_transform(Y)


#splitting the dataset in trainning and test
from sklearn.cross_validation import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)


#Feature Scaling - normalizing data
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)


#fITTING sIMPLE lINEAR rEGRESSION TO THE tRAININNG SET
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, Y_train)



#Predicting the test set
Y_Prediction = regressor.predict(X_test)

#plotting the results X_train
plt.scatter(X_train, Y_train, color = 'red') 
plt.plot(X_train, regressor.predict(X_train), color = 'blue' )
#Adding tittle and x and y labels
plt.title('Salary vs Experience (Training set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
#plt.show() to end the plot
plt.show()


#plotting the results X_test
plt.scatter(X_test, Y_test, color = 'red') 
plt.plot(X_train, regressor.predict(X_train), color = 'blue' )
plt.title('Salary vs Experience (Test set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()


###########################################33
#R

dataset = read.csv('Data.csv')

#replacing nan values for the ave 
dataset$Column = ifelse(is.na(dataset$Column),
                     ave(dataset$Column, FUN = function(x) mean(x, na.rm = TRUE)),
                     dataset$Column)

dataset$Column2 = ifelse(is.na(dataset$Column2),
                        ave(dataset$Column2, FUN = function(x) mean(x, na.rm = TRUE)),
                        dataset$Column2)


#encoder data in R is much easier to understand and apply than python (my opnion).
dataset$Column = factor(dataset$Column,
                         levels = c('values1','values2', 'values3'),
                         labels = c(1,2,3))

dataset$Column2 = factor(dataset$Column,
                         levels = c('values0', 'values1', 'values2', 'values3', 'values4', 'values5'),
                         labels = c(0,1,2,3,4,5))
						 
#Splitting the dataset in training and test
library(caTools)
set.seed(123)
split = sample.split(dataset$Column, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

#Feature Scaling in the columns 2 and 3, if you want all columns just 
#skip the [, 2:3] field
training_set[, 2:3] = scale(training_set[, 2:3])
test_set[, 2:3] = scale(test_set[, 2:3])



